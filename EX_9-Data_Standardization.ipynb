{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h1 style=\"font-size:30px;text-align: center;\">- Date Engineering  - Exercise 9 -</h1></b>\n",
    "<b><h1 style=\"font-size:25px;text-align: center;\">- Data Standardization -</h1></b>\n",
    "\n",
    "<center><img src=\"https://www.algebra.hr/sveuciliste/wp-content/uploads/2023/11/algebra_UNIVERSITY-1-800x242.png\"/></center>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<b>*Made: December 2024.* </b>\n",
    "\n",
    "<b>*Author: Mislav SpajiÄ‡, mag. ing. comp.*</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOvht7vqQGdR",
    "papermill": {
     "duration": 0.030335,
     "end_time": "2020-11-27T11:52:28.446538",
     "exception": false,
     "start_time": "2020-11-27T11:52:28.416203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dB_j6LtTTO5j",
    "papermill": {
     "duration": 0.02728,
     "end_time": "2020-11-27T11:52:28.666647",
     "exception": false,
     "start_time": "2020-11-27T11:52:28.639367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data standardization in the broader sense is the process of transforming data from various sources into one common format so that all data in a dataset has the same structure and meaning.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This definition outlines the overarching goal of standardizing data, which is to:**\n",
    "\n",
    "* Integrate Data from Diverse Sources: Combine data that may have originated from different systems, applications, or formats into a unified structure.\n",
    "\n",
    "* Ensure Uniformity in Structure and Meaning: Make sure that all data follows the same schema, conventions, and interpretations, so it can be compared, analyzed, and processed effectively.\n",
    "\n",
    "**Broader Context of Data Standardization**\n",
    "* It is not limited to just a specific task like unit conversion, format normalization, or data type consistency. Instead, it encompasses all processes aimed at achieving uniformity and comparability.\n",
    "* Examples in the broader sense include:\n",
    "    * Harmonizing terminologies across datasets (e.g., \"USA\" vs. \"United States\" vs. \"US\").\n",
    "    * Aligning data types (e.g., ensuring dates are stored as YYYY-MM-DD format everywhere).\n",
    "    * Resolving discrepancies in measurement units (e.g., standardizing financial data in one currency).\n",
    "    * Removing ambiguity in categorical values (e.g., consolidating gender entries like \"Male\" and \"M\" into \"M\").\n",
    "\n",
    "---\n",
    "* This broad definition emphasizes that standardization is foundational to integrating and using data effectively, especially in contexts like data warehousing, business intelligence, or machine learning, where consistent structure and meaning are critical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hg00soETQ3z",
    "papermill": {
     "duration": 0.027462,
     "end_time": "2020-11-27T11:52:28.721524",
     "exception": false,
     "start_time": "2020-11-27T11:52:28.694062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Data standardization includes processes such as:**\n",
    "\n",
    "* Converting units (e.g., transferring all data values from miles to kilometers)\n",
    "\n",
    "* Normalizing formats (e.g., standardizing date formats, metrics, or currencies, removing redundancy)\n",
    "\n",
    "* Ensuring consistency in data type (e.g., maintaining consistent capitalization and naming conventions in one standard format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQDO4JCqTThV",
    "papermill": {
     "duration": 0.027108,
     "end_time": "2020-11-27T11:52:28.885282",
     "exception": false,
     "start_time": "2020-11-27T11:52:28.858174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPSqz1wzTXvz",
    "papermill": {
     "duration": 0.027001,
     "end_time": "2020-11-27T11:52:28.939572",
     "exception": false,
     "start_time": "2020-11-27T11:52:28.912571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Importing the required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eLMx1Ebwa92",
    "papermill": {
     "duration": 0.027148,
     "end_time": "2020-11-27T11:52:28.994036",
     "exception": false,
     "start_time": "2020-11-27T11:52:28.966888",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below are the libraries that are used in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGyDovL2QDLa",
    "papermill": {
     "duration": 1.032787,
     "end_time": "2020-11-27T11:52:30.054137",
     "exception": false,
     "start_time": "2020-11-27T11:52:29.021350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ye6eXuohTd5Q",
    "papermill": {
     "duration": 0.028147,
     "end_time": "2020-11-27T11:52:30.110492",
     "exception": false,
     "start_time": "2020-11-27T11:52:30.082345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Y3Z2DbKTfJt",
    "papermill": {
     "duration": 0.027409,
     "end_time": "2020-11-27T11:52:30.165749",
     "exception": false,
     "start_time": "2020-11-27T11:52:30.138340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Converting Units (Height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oVZnezwQ159",
    "outputId": "f1e0fe18-8fa0-482a-e2b9-2ecd87d97d9d",
    "papermill": {
     "duration": 0.104836,
     "end_time": "2020-11-27T11:52:30.409177",
     "exception": false,
     "start_time": "2020-11-27T11:52:30.304341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Creating a dataset of heights with mixed units\n",
    "names = ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'Grace', 'Hank', 'Ivy', 'Jack',\n",
    "         'Karen', 'Leo', 'Mona', 'Nina', 'Oscar', 'Paul', 'Quincy', 'Rose', 'Steve', 'Tina']\n",
    "units = ['cm', 'inch']\n",
    "\n",
    "# Generate random heights and units for 20 individuals\n",
    "heights = pd.DataFrame({\n",
    "    'Name': names,\n",
    "    'Unit': [random.choice(units) for _ in range(20)]\n",
    "})\n",
    "\n",
    "# Assign heights based on the unit\n",
    "heights['Height'] = heights['Unit'].apply(\n",
    "    lambda unit: random.randint(55, 80) if unit == 'inch' else random.randint(140, 200)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fm-9dzdTRKpe",
    "outputId": "7892eaf7-0605-4b92-e139-cf0553041e51",
    "papermill": {
     "duration": 0.052534,
     "end_time": "2020-11-27T11:52:30.490899",
     "exception": false,
     "start_time": "2020-11-27T11:52:30.438365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the issue (before standardization)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist([heights.loc[heights['Unit'] == 'cm', 'Height'], \n",
    "          heights.loc[heights['Unit'] == 'inch', 'Height'] ], \n",
    "         label=['Original cm', 'Original inch'], bins=20, alpha=0.7)\n",
    "plt.title(\"Height Distribution Before Standardization\")\n",
    "plt.xlabel(\"Height\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function for conversion\n",
    "\n",
    "# Converting all heights to cm\n",
    "def convert_to_cm(row):\n",
    "    if row['Unit'] == 'inch':\n",
    "        return row['Height'] * 2.54\n",
    "    return row['Height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying it\n",
    "heights['Height_cm'] = heights.apply(convert_to_cm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting after\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(heights['Height_cm'], \n",
    "         label=['Converted cm'], bins=20, alpha=0.7)\n",
    "plt.title(\"Height Distribution After Standardization\")\n",
    "plt.xlabel(\"Height\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjQnr4SPzaL5",
    "papermill": {
     "duration": 0.029003,
     "end_time": "2020-11-27T11:52:30.549371",
     "exception": false,
     "start_time": "2020-11-27T11:52:30.520368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAmC369yTpMF",
    "papermill": {
     "duration": 0.029103,
     "end_time": "2020-11-27T11:52:30.608838",
     "exception": false,
     "start_time": "2020-11-27T11:52:30.579735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Normalizing Formats (Dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPbKQ0noRptD",
    "outputId": "6a5aea47-ad0c-4118-8471-d91b6432b339",
    "papermill": {
     "duration": 0.040549,
     "end_time": "2020-11-27T11:52:30.738002",
     "exception": false,
     "start_time": "2020-11-27T11:52:30.697453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a dataset with inconsistent date formats\n",
    "dates = pd.DataFrame({\n",
    "    'Event': ['Meeting', 'Workshop', 'Conference', 'Webinar', 'Summit', 'Lab'],\n",
    "    'Date': ['01/15/2023', '2023-01-10', '16 Jan 2023', '10-01-2023', 'January 18, 2023', 'January 23, 22']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all dates to a standardized format (YYYY-MM-DD)\n",
    "dates['Standardized_Date'] = pd.to_datetime(dates['Date'])\n",
    "print(dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all dates to a standardized format (YYYY-MM-DD) using mixed format option\n",
    "dates['Standardized_Date'] = pd.to_datetime(dates['Date'],format='mixed')\n",
    "print(dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dayfirst argument\n",
    "dates['Standardized_Date2'] = pd.to_datetime(dates['Date'],format='mixed', dayfirst = True)\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beRJyQAezdX8",
    "papermill": {
     "duration": 0.029309,
     "end_time": "2020-11-27T11:52:30.797064",
     "exception": false,
     "start_time": "2020-11-27T11:52:30.767755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ensuring Consistency in Data Types (Formats) (Gender example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataset with inconsistent gender values\n",
    "gender_data = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank'],\n",
    "    'Gender': ['F', 'M', 'O', 'Male', 'Female', 'Other']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing gender to 'M', 'F', 'O' using map and dictionary\n",
    "gender_mapping = {\n",
    "    'F': 'F', 'Female': 'F',\n",
    "    'M': 'M', 'Male': 'M',\n",
    "    'O': 'O', 'Other': 'O'\n",
    "}\n",
    "gender_data['Standardized_Gender'] = gender_data['Gender'].map(gender_mapping)\n",
    "print(gender_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoHuBhXxT5E9",
    "papermill": {
     "duration": 0.029086,
     "end_time": "2020-11-27T11:52:30.855758",
     "exception": false,
     "start_time": "2020-11-27T11:52:30.826672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Ensuring Consistency in Data Types (Formats) (Location example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, import data using the pandas library and convert them into a dataframe. Through the `head(10)` method we print only the first 10 rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets.csv')\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorrect data types\n",
    "First of all, we should make sure that every column is assigned to the correct data type. This can be checked through the property `dtypes`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we can convert the column `Tweet Location` to `string` by using the function `astype()` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweet Location'] = df['Tweet Location'].astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `astype()` function supports all datatypes described at [this link](https://www.pytables.org/usersguide/datatypes.html).\n",
    "\n",
    "## Make the data homogeneous\n",
    "This aspect involves categorical and numeric data. Categorical data should have all the same formatting style, such as lower case. Numeric data should have for example the same number of digits after the point. In order to format all categorical data to lower case, we can use the following statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweet Content'] = df['Tweet Content'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different values for the same concept\n",
    "It may happen that the same concept is represented in different ways. For example, in our dataset, the column `Twitter Location` contains the values `Columbus,OH` and `Columbus, OH` to describe the same concept. We can use the `unique()` function to list all the values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Tweet Location'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to deal with different values representing the same concept, we should manipulate each type of error separately. For example, we can manipulate every string `word,word` in order to insert a space after the comma and have the following output `word, word`. We can define a function, called `set_pattern()` which searches for a specific pattern into a string and then it performs some replacement in the same string, if the pattern is found. In our case we search for all the patterns having the structure `word,word` and then we replace the `,` with `, `. Finally we return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def set_pattern(x):\n",
    "    pattern = r'[(A-Z)]\\w+,([A-Z])\\w+'\n",
    "    res = re.match(pattern, x)\n",
    "    if res:\n",
    "        x = x.replace(',', ', ')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the function to every value in the column `Tweet Location`. This can be achieved by using the function `apply()` combined with the operator `lambda`. We can specify that the function `apply()` must be applied to every row (through the parameter `axis = 1`) and then through the `lambda` operator we can select the specific row and apply it the function `set_pattern()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweet Location'] = df['Tweet Location'].apply(lambda x: set_pattern(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweet Location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "papermill": {
   "duration": 12.885345,
   "end_time": "2020-11-27T11:52:37.154623",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-27T11:52:24.269278",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
